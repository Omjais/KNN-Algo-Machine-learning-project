KNN Classification
This repository contains a Jupyter notebook implementing a K-Nearest Neighbors (KNN) classifier to predict underweight status based on features from a dataset.

ğŸ“‚ Project Structure
Copy
Edit
ğŸ“¦ KNN_Classification/
 â”£ ğŸ“„ KNN_Classifiacton(Irisflower).ipynb
 â”— ğŸ“„ README.md
ğŸ“ˆ Overview
Dataset: The notebook uses data from
https://www.kaggle.com/datasets/saurabh00007/iriscsv

Features: The first two columns are used as predictors (features).

Target: The last column represents the class label (underweight status).

ğŸš€ Steps Performed
âœ… Data loading using Pandas
âœ… Feature extraction (x) and target extraction (y)
âœ… Model creation with KNeighborsClassifier (n_neighbors=15)
âœ… Model training
âœ… Prediction on training data
âœ… Evaluation using accuracy score and confusion matrix

ğŸ›  Requirements
Install dependencies using:

bash
Copy
Edit
pip install pandas scikit-learn
ğŸ’» How to Run
1ï¸âƒ£ Clone this repository:

bash
Copy
Edit
git clone https://github.com/your-username/your-repo-name.git
2ï¸âƒ£ Navigate to the project directory:

bash
Copy
Edit
cd your-repo-name
3ï¸âƒ£ Run the notebook:

bash
Copy
Edit
jupyter notebook KNN_Classifiacton(Irisflower).ipynb
ğŸ“Š Results
Accuracy: The model computes the accuracy on the training data.

Confusion Matrix: The confusion matrix is generated to evaluate performance.

ğŸ‘‰ Note: The current implementation predicts on the same data used for training. For realistic evaluation, consider splitting the dataset (e.g., using train_test_split).

âœï¸ Author
Om Jaiswal
https://github.com/Omjais
